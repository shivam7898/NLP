# NLP Basics {#p01}

```{r 'P01-R', decorate=TRUE, include=FALSE, cache=FALSE}
sys.source(here::here("code", "A00Knitr.R"), envir = knitr::knit_global())
sys.source(here::here("code", "A01Packages.R"), envir = knitr::knit_global())
sys.source(here::here("code", "A02AllUDF.R"), envir = knitr::knit_global())
reticulate::source_python(here::here("code", "B01Modules.py"), convert = FALSE)
sys.source(here::here("code", "A04PackagesPython.R"), envir = knitr::knit_global())
```

```{r 'P01-R-Limit-Knit-Build', decorate=TRUE, include=FALSE, eval=FALSE}
# #To only evaluate up to this chunk and complete the knit process.
knit_exit()
```

## Data: Krackhardt Kite {#kite-p01 .tabset .tabset-fade}

### Glance R {.unlisted .unnumbered}

\textcolor{pink}{Please import the "P01-Kite.csv"}

- About: 18 Edges and 10 Vertices

```{r 'P01-R-CSV-Kite', decorate=TRUE, include=FALSE}
loc_src <- here("data", "P01-Kite.csv")
loc_bin <- here("data", "P01-R-Kite.feather")
#
if(FALSE | !file.exists(loc_bin)) {
  # #Read Adjacency Matrix from CSV 
  aa <- read_csv(loc_src, show_col_types = FALSE)
  # #Drop Column | Coercion |
  aa <- aa |> select(-Nodes) |> mutate(across(everything(), as.integer))
  # #Save as Feather
  write_feather(aa, loc_bin)
} else {# #Read Feather
  aa <- read_feather(loc_bin)
}

# #Copy
p01r_kite <- aa
```

```{r 'P01-R-Structure-Kite', decorate=TRUE}
str(p01r_kite)
```

### CSV to R {.unlisted .unnumbered}

```{r 'P01-R-CSV-Kite-A', decorate=TRUE, eval=FALSE, ref.label=c('P01-R-CSV-Kite')}
#
```

### CSV to Python {.unlisted .unnumbered}

```{python 'P01-Y-CSV-Kite', decorate=TRUE}
loc_src = "data/P01-Kite.csv"
loc_bin = "data/P01-Y-Kite.feather"
if(os.path.isdir("data")):
    # #If TRUE (Build, Knit, Console), Else (Manual Chunk)
    #loc_src = "./" + loc_src if os.path.isdir("data") else "./../" + loc_src
    loc_src = "./" + loc_src
    loc_bin = "./" + loc_bin
else:
    loc_src = "./../" + loc_src
    loc_bin = "./../" + loc_bin

if(False or not(os.path.exists(loc_bin))):
    # #Read Adjacency Matrix from CSV using Pandas
    pp = pd.read_csv(loc_src)
    # #Drop Columns
    pp.drop(columns = ['Nodes'], inplace = True)
    # #Coercion
    pp = pp.astype(np.int32)
    # #Save as Feather
    pyarrow.feather.write_feather(pp, loc_bin)
else:
    # #Read Feather
    pp = pd.read_feather(loc_bin)

# #Copy
p01y_kite = pp.copy()

```

### Glance Python {.unlisted .unnumbered}

```{python 'P01-Y-Glance', decorate=TRUE}
# #Type, Shape, All Column Names, Null Count, Drop NA, Column Type, Head, Numeric Column Summary
pp = p01y_kite.copy()
print(type(pp))

pp.shape

print(pp.columns.tolist())
print(pp.columns.values)

print(pp.isnull().sum())

pp = pp.dropna()

pp.info()

pp.head(n = 3)

pp.describe()

```

### R to Python {.unlisted .unnumbered}

```{python 'P01-Y-R2Y-Kite', decorate=TRUE}
# #R DataFrame | Pandas DataFrame | Copy | NumPy Structured Array | 
p01y_kite_pd = r.p01r_kite
# #Verify that DataFrame Copied from R Matches the one in Python
assert(p01y_kite_pd.equals(p01y_kite))
#
pp = p01y_kite_pd.copy()
qq = np.array([tuple(Row) for Row in pp.to_numpy(copy = True)], dtype = list(pp.dtypes.items()))
p01y_kite_np = qq.copy()
print(p01y_kite_np)
del(p01y_kite_pd, p01y_kite_np)

```

### Python to R {.unlisted .unnumbered}

```{r 'P01-R-Y2R-Kite', decorate=TRUE}
p01r_kite_tbl <- py$p01y_kite |> 
  mutate(across(where(is.numeric), as.integer)) |> 
  `attr<-`("pandas.index", NULL) |> as_tibble()
# #Verify that DataFrame Copied from Python Matches the one in R
stopifnot(identical(p01r_kite_tbl, p01r_kite))
# #DataFrame to Matrix
p01r_kite_mat <- as.matrix.data.frame(p01r_kite)
print(p01r_kite_mat)
rm(p01r_kite_tbl, p01r_kite_mat)
```

### Feather: R & Python {.unlisted .unnumbered}

```{r 'P01-R-Match-Feather', decorate=TRUE}
# #Read in R the Feather file that was written by Python
loc_bin <- here("data", "P01-Y-Kite.feather")
aa <- read_feather(loc_bin)
stopifnot(identical(aa, p01r_kite))
str(aa)
```

```{python 'P01-Y-Match-Feather', decorate=TRUE}
# #Read in Python the Feather file that was written by R
loc_bin = "data/P01-R-Kite.feather"
loc_bin = "./" + loc_bin if os.path.isdir("data") else "./../" + loc_bin
pp = pd.read_feather(loc_bin)
assert(pp.equals(p01y_kite))
pp.info()

```

## Data: KM Network {#km-p01 .tabset .tabset-fade}

### Glance R {.unlisted .unnumbered}

\textcolor{pink}{Please import the "P01-KM-Week1.xlsx" and "P01-KM-Week4.xlsx"}

- About: Edges and Vertices of a Class Network at Week 1 and Week 4

```{r 'P01-R-XL-KM-1', decorate=TRUE, include=FALSE}
loc_src <- here("data", "P01-KM-Week1.xlsx")
loc_rds <- here("data", "P01-R-KM-Week1.rds")
if(FALSE | !file.exists(loc_rds)) {
  names_aa <- c("Edges", "Vertices")
  # #Verify Excel
  stopifnot(identical(excel_sheets(loc_src), names_aa))
  # #Empty Named List
  aa <- setNames(vector("list", length(names_aa)), nm = names_aa)
  # #Read Excel Sheets
  aa$Edges    <- read_excel(path = loc_src, sheet = "Edges")
  aa$Vertices <- read_excel(path = loc_src, sheet = "Vertices")
  #
  # #Clean Edges
  names_bb <- c("Node_1", "Node_2", "Recognition", "Friendship")
  # #Rename | To Factor |
  bb <- aa$Edges |> rename_with(make.names) |> 
    rename_with(~ tolower(gsub(".", "_", .x, fixed = TRUE))) |> 
    mutate(across(starts_with("vertex_"), factor)) |> 
    mutate(across(c(recognition, friendship), factor, levels = c(0, 1), labels = c("No", "Yes")))
  # #Rename
  names(bb) <- names_bb
  aa$Edges <- bb
  #
  # #Clean Vertices
  names_bb <- c("Node", "Gender", "Status", "ACCT", "IE", "MS_MIS", "MBA", "Group", "Major")
  # #Rename | Replace NA | Replace x | To Factor |
  bb <- aa$Vertices |> rename_with(make.names) |> 
    rename_with(~ tolower(gsub(".", "_", .x, fixed = TRUE))) |> 
    mutate(across(c(acct, ie, ms_mis, mba), ~ replace_na(., "No"))) |> 
    mutate(across(c(acct, ie, ms_mis, mba), ~gsub("x", "Yes", .))) |> 
    mutate(across(where(is.character), factor))
  # #Rename
  names(bb) <- names_bb
  aa$Vertices <- bb
  #
  # #Save
  p01r_km_1 <- aa
  saveRDS(p01r_km_1, loc_rds)
} else { 
  p01r_km_1 <- aa <- readRDS(loc_rds)
}
```

```{r 'P01-R-XL-KM-4', decorate=TRUE, include=FALSE}
loc_src <- here("data", "P01-KM-Week4.xlsx")
loc_rds <- here("data", "P01-R-KM-Week4.rds")
if(FALSE | !file.exists(loc_rds)) {
  names_aa <- c("Edges", "Vertices")
  # #Verify Excel
  stopifnot(identical(excel_sheets(loc_src), names_aa))
  # #Empty Named List
  aa <- setNames(vector("list", length(names_aa)), nm = names_aa)
  # #Read Excel Sheets
  aa$Edges    <- read_excel(path = loc_src, sheet = "Edges")
  aa$Vertices <- read_excel(path = loc_src, sheet = "Vertices")
  #
  # #Clean Edges
  names_bb <- c("Node_1", "Node_2", "Recognition", "Friendship")
  # #Rename | To Factor |
  bb <- aa$Edges |> rename_with(make.names) |> 
    rename_with(~ tolower(gsub(".", "_", .x, fixed = TRUE))) |> 
    mutate(across(starts_with("vertex_"), factor)) |> 
    mutate(across(c(recognition, friendship), factor, levels = c(0, 1), labels = c("No", "Yes")))
  # #Rename
  names(bb) <- names_bb
  aa$Edges <- bb
  #
  # #Clean Vertices
  names_bb <- c("Node", "Gender", "Status", "ACCT", "IE", "MS_MIS", "MBA", "Group", "Major")
  # #Rename | Replace NA | Replace x | To Factor |
  bb <- aa$Vertices |> rename_with(make.names) |> 
    rename_with(~ tolower(gsub(".", "_", .x, fixed = TRUE))) |> 
    mutate(across(c(acct, ie, ms_mis, mba), ~ replace_na(., "No"))) |> 
    mutate(across(c(acct, ie, ms_mis, mba), ~gsub("x", "Yes", .))) |> 
    mutate(across(where(is.character), factor))
  # #Rename
  names(bb) <- names_bb
  aa$Vertices <- bb
  #
  # #Save
  p01r_km_4 <- aa
  saveRDS(p01r_km_4, loc_rds)
} else { 
  p01r_km_4 <- aa <- readRDS(loc_rds)
}
```

```{r 'P01-R-Dimensions-KM', decorate=TRUE}
# #Dimensions of Each Sheet: Row 1 (Rows), Row 2 (Columns), Columns (Sheets)
vapply(p01r_km_1, dim, numeric(2))
vapply(p01r_km_4, dim, numeric(2))
```

### Structure R {.unlisted .unnumbered}

```{r 'P01-R-Structure-KM', decorate=TRUE}
str(p01r_km_1)
str(p01r_km_4)
```

### Summary R {.unlisted .unnumbered}

```{r 'P01-R-Summary-KM', decorate=TRUE}
# #Summary of List Objects
lapply(p01r_km_1, summary)
lapply(p01r_km_4, summary)
```

### Excel to R {.unlisted .unnumbered}

```{r 'P01-R-XL-KM-1-A', decorate=TRUE, eval=FALSE, ref.label=c('P01-R-XL-KM-1')}
#
```

```{r 'P01-R-XL-KM-4-A', decorate=TRUE, eval=FALSE, ref.label=c('P01-R-XL-KM-4')}
#
```

### ETC {.unlisted .unnumbered}

```{r 'P01-R-ETC', decorate=TRUE, include=TRUE, eval=FALSE}
# #Count NA in Columns
if(FALSE) colSums(is.na(bb)) |> as_tibble(rownames = "Cols") |> filter(value > 0)
# #Subset Rows
if(FALSE) bb |> select(1) |> slice(1:10)
# #Comma separated string having each item within quotes for easy pasting as character not objects
if(FALSE) cat('"', paste0(names(which(sapply(bb, is.factor))), collapse = '", "'), '"\n', sep = '')
if(FALSE) cat('"', paste0(levels(bb$Arrival), collapse = '", "'), '"\n', sep = '')
# #Filter
if(FALSE) bb |> filter(is.na(account_length)) |> select(churn, account_length, vmail_plan)
# #Count Yes/No or True/False in ALL such Columns
if(FALSE) bb |> select(churn) |> 
  pivot_longer(everything()) |> count(name, value) |> 
  pivot_wider(names_from = value, values_from = n)
# #Count Unique of all Columns to decide which should be Factors
if(FALSE) bb |> summarise(across(everything(), ~ length(unique(.)))) |> pivot_longer(everything())
# #Summary of Columns of a class: is.factor is.numeric is.character
if(FALSE) bb |> select(where(is.factor)) |> summary()
# #Names and Indices of Columns of class: is.factor is.numeric is.character
if(FALSE) which(sapply(bb, is.factor))
# #Levels of Factor Columns
if(FALSE) lapply(bb[c(3, 6:9, 15)], levels)
# #Frequency of Each level of Factor
if(FALSE) bb |> count(churn) |> arrange(desc(n))
# #Coding for Dummy Variables
if(FALSE) contrasts(bb$Married) 
# #Vector of all column classes
if(FALSE) bb |> {\(x) vapply(x, class, character(1))}()
```

### Glance Python {.unlisted .unnumbered}

```{python 'P01-Y-XL-KM-1', decorate=TRUE, include=FALSE}
loc_src = "data/P01-KM-Week1.xlsx"
loc_bin_e = "data/P01-Y-KM-Week-1-Edges.feather"
loc_bin_v = "data/P01-Y-KM-Week-1-Vertices.feather"

if(os.path.isdir("data")):
    # #If TRUE (Build, Knit, Console), Else (Manual Chunk)
    #loc_src = "./" + loc_src if os.path.isdir("data") else "./../" + loc_src
    loc_src = "./" + loc_src
    loc_bin_e = "./" + loc_bin_e
    loc_bin_v = "./" + loc_bin_v
else:
    loc_src = "./../" + loc_src
    loc_bin_e = "./../" + loc_bin_e
    loc_bin_v = "./../" + loc_bin_v

# #Delete if Exists
if 'pp' in globals(): del(pp)

if(False or not(os.path.exists(loc_bin_e)) or not(os.path.exists(loc_bin_v))):
    # #Read Excel Sheets as Dictionary of DataFrames
    pp = pd.read_excel(loc_src, sheet_name = None)
    # #Type
    print(type(pp))
    
    # #Number of Sheets
    len(pp)
    
    # #Names of Sheets
    print(pp.keys())
    
    # #Type of Dictionary Elements
    print(type(pp['Edges']))
    print(type(pp['Vertices']))
    
    # #Copy for Modifications: Edges
    qq = pp['Edges'].copy()
    
    # #Column Headers of Key Edges
    print(qq.columns.tolist())
    
    # #Rename Headers of Key Edges by mapping old names to new names
    qq.rename(columns = {"Vertex 1": "Node_1", "Vertex 2": "Node_2"}, inplace = True)
    
    # #Convert Some Columns to String using subset selection
    qq[['Recognition', 'Friendship']] = qq[['Recognition', 'Friendship']].astype(str)
    
    # #Replace specific values in columns
    qq.loc[qq['Recognition'] == "0", 'Recognition'] = "No"
    qq.loc[qq['Recognition'] == "1", 'Recognition'] = "Yes"
    qq.loc[qq['Friendship'] == "0", 'Friendship'] = "No"
    qq.loc[qq['Friendship'] == "1", 'Friendship'] = "Yes"
    
    # #Get a list of column names of specific datatype
    cols = qq.select_dtypes(include=['object']).columns.to_list()
    # #Coerce multiple columns having their column names in a list
    qq[cols] = qq[cols].astype('category')
    
    # #Save the Modifications back to Original
    pp['Edges'] = qq
    
    # #Copy for Modifications: Vertices
    qq = pp['Vertices'].copy()
    
    # #Column Headers of Key Vertices
    old_names = qq.columns.tolist()
    print(old_names)
    
    # #Rename Headers of Key Vertices by mapping old names to new names after zipping old & new
    new_names = ['Node', 'Gender', 'Status', 'ACCT', 'IE', 'MS-MIS', 'MBA', 'Group', 'Major']
    qq.rename(columns = dict(zip(old_names, new_names)), inplace = True)
    print(qq.columns.tolist())
    
    # #Replace a Value in Multiple Columns
    cols = ['ACCT', 'IE', 'MS-MIS', 'MBA']
    qq[cols] = qq[cols].replace({'x':'Yes'})
    
    # #Replace NaN in Multiple Columns
    qq[cols] = qq[cols].fillna('No')
    
    # #Get a list of column names of specific datatype
    cols = qq.select_dtypes(include = ['object']).columns.to_list()
    # #Coerce multiple columns having their column names in a list
    qq[cols] = qq[cols].astype('category')
    
    # #Save the Modifications back to Original
    pp['Vertices'] = qq
    
    # #Save as Feather
    pyarrow.feather.write_feather(pp['Edges'], loc_bin_e)
    pyarrow.feather.write_feather(pp['Vertices'], loc_bin_v)
else:
    # #Read Feather
    pp = {
        "Edges": pd.read_feather(loc_bin_e),
        "Vertices": pd.read_feather(loc_bin_v)
    }

#
# #Save a deepcopy
p01y_km_1 = copy.deepcopy(pp)

```

```{python 'P01-Y-XL-KM-4', decorate=TRUE, include=FALSE}
loc_src = "data/P01-KM-Week4.xlsx"
loc_bin_e = "data/P01-Y-KM-Week-4-Edges.feather"
loc_bin_v = "data/P01-Y-KM-Week-4-Vertices.feather"

if(os.path.isdir("data")):
    # #If TRUE (Build, Knit, Console), Else (Manual Chunk)
    #loc_src = "./" + loc_src if os.path.isdir("data") else "./../" + loc_src
    loc_src = "./" + loc_src
    loc_bin_e = "./" + loc_bin_e
    loc_bin_v = "./" + loc_bin_v
else:
    loc_src = "./../" + loc_src
    loc_bin_e = "./../" + loc_bin_e
    loc_bin_v = "./../" + loc_bin_v

# #Delete if Exists
if 'pp' in globals(): del(pp)

if(False or not(os.path.exists(loc_bin_e)) or not(os.path.exists(loc_bin_v))):
    # #Read Excel Sheets as Dictionary of DataFrames
    pp = pd.read_excel(loc_src, sheet_name = None)
    # #Type
    print(type(pp))
    
    # #Number of Sheets
    len(pp)
    
    # #Names of Sheets
    print(pp.keys())
    
    # #Type of Dictionary Elements
    print(type(pp['Edges']))
    print(type(pp['Vertices']))
    
    # #Copy for Modifications: Edges
    qq = pp['Edges'].copy()
    
    # #Column Headers of Key Edges
    print(qq.columns.tolist())
    
    # #Rename Headers of Key Edges by mapping old names to new names
    qq.rename(columns = {"Vertex 1": "Node_1", "Vertex 2": "Node_2"}, inplace = True)
    
    # #Convert Some Columns to String using subset selection
    qq[['Recognition', 'Friendship']] = qq[['Recognition', 'Friendship']].astype(str)
    
    # #Replace specific values in columns
    qq.loc[qq['Recognition'] == "0", 'Recognition'] = "No"
    qq.loc[qq['Recognition'] == "1", 'Recognition'] = "Yes"
    qq.loc[qq['Friendship'] == "0", 'Friendship'] = "No"
    qq.loc[qq['Friendship'] == "1", 'Friendship'] = "Yes"
    
    # #Get a list of column names of specific datatype
    cols = qq.select_dtypes(include=['object']).columns.to_list()
    # #Coerce multiple columns having their column names in a list
    qq[cols] = qq[cols].astype('category')
    
    # #Save the Modifications back to Original
    pp['Edges'] = qq
    
    # #Copy for Modifications: Vertices
    qq = pp['Vertices'].copy()
    
    # #Column Headers of Key Vertices
    old_names = qq.columns.tolist()
    print(old_names)
    
    # #Rename Headers of Key Vertices by mapping old names to new names after zipping old & new
    new_names = ['Node', 'Gender', 'Status', 'ACCT', 'IE', 'MS-MIS', 'MBA', 'Group', 'Major']
    qq.rename(columns = dict(zip(old_names, new_names)), inplace = True)
    print(qq.columns.tolist())
    
    # #Replace a Value in Multiple Columns
    cols = ['ACCT', 'IE', 'MS-MIS', 'MBA']
    qq[cols] = qq[cols].replace({'x':'Yes'})
    
    # #Replace NaN in Multiple Columns
    qq[cols] = qq[cols].fillna('No')
    
    # #Get a list of column names of specific datatype
    cols = qq.select_dtypes(include = ['object']).columns.to_list()
    # #Coerce multiple columns having their column names in a list
    qq[cols] = qq[cols].astype('category')
    
    # #Save the Modifications back to Original
    pp['Vertices'] = qq
    
    # #Save as Feather
    pyarrow.feather.write_feather(pp['Edges'], loc_bin_e)
    pyarrow.feather.write_feather(pp['Vertices'], loc_bin_v)
else:
    # #Read Feather
    pp = {
        "Edges": pd.read_feather(loc_bin_e),
        "Vertices": pd.read_feather(loc_bin_v)
    }

#
# #Save a deepcopy
p01y_km_4 = copy.deepcopy(pp)

```

```{python 'P01-Y-Head-KM', decorate=TRUE}
print(p01y_km_1['Edges'].shape)
print(p01y_km_1['Vertices'].shape)
print(p01y_km_4['Edges'].shape)
print(p01y_km_4['Vertices'].shape)
#
print(p01y_km_1['Edges'].head())
print(p01y_km_1['Vertices'].head())
print(p01y_km_4['Edges'].head())
print(p01y_km_4['Vertices'].head())

```

### Excel to Python {.unlisted .unnumbered}

```{python 'P01-Y-XL-KM-1-A', decorate=TRUE, eval=FALSE, ref.label=c('P01-Y-XL-KM-1')}
#
```

```{python 'P01-Y-XL-KM-4-A', decorate=TRUE, eval=FALSE, ref.label=c('P01-Y-XL-KM-4')}
#
```

## Network

```{definition 'Network'}
A \textcolor{pink}{network} is a collection of entities and their relationships to one another. The entities that are connected are called \textcolor{pink}{nodes (vertices)}. The connections between the vertices are called \textcolor{pink}{edges (links)}.
```

## Kite

### Undirected and Directed Graphs

- \textcolor{pink}{Undirected}: $\quad A[i, j] = 1 \quad\Rightarrow\quad A[j, i] = 1$
- \textcolor{pink}{Directed} &nbsp; &nbsp; &nbsp;: $\quad A[i, j] = 1 \quad\nRightarrow\quad A[j, i] = 1$

### iGraph & Adjacency Matrix {.tabset .tabset-fade}

- \textcolor{pink}{iGraph} object description has 4 letters and 2 numbers
  - D or U, for a directed or undirected graph
  - N for a named graph (where nodes have a \textcolor{pink}{name} attribute)
  - W for a weighted graph (where edges have a \textcolor{pink}{weight} attribute)
  - B for a bipartite (two-mode) graph (where nodes have a \textcolor{pink}{type} attribute)
  - Numbers: Nodes (or Vertices) and Edges
  - The description also lists node & edge attributes, for example:
    - (g/c) - graph-level character attribute
    - (v/c) - vertex-level character attribute
    - (e/n) - edge-level numeric attribute

#### R {.unlisted .unnumbered}

```{r 'P01-R-iGraph-Kite', decorate=TRUE}
# #DataFrame to Matrix
bb <- as.matrix.data.frame(p01r_kite)
# #Get iGraph (Undirected) from Adjacency Matrix
kite_u <- graph_from_adjacency_matrix(bb, mode = "undirected")
kite_u
#
# #Get iGraph (Directed) from Adjacency Matrix
kite_d <- graph_from_adjacency_matrix(bb, mode = "directed")
kite_d
#
r_kite <- kite_u
class(r_kite)
#
# #Get Adjacency Matrix from iGraph (Undirected)
ii <- as_adjacency_matrix(kite_u, type = "both", sparse = FALSE) |> apply(2, as.integer)
rownames(ii) <- NULL
# #Get Adjacency Matrix from iGraph (Directed)
jj <- as_adjacency_matrix(kite_d, sparse = FALSE) |> apply(2, as.integer)
rownames(jj) <- NULL
stopifnot(all(identical(bb, ii), identical(bb, jj)))
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-iGraph-Kite', decorate=TRUE}
# #DataFrame | NumPy Structured Array (Adjacency Matrix) | List | D iGraph | U iGraph |
pp = p01y_kite.copy()
qq = np.array([tuple(Row) for Row in pp.to_numpy(copy = True)], dtype = list(pp.dtypes.items()))

# #Get iGraph (Directed) from Adjacency Matrix
kite_d = ig.Graph.Adjacency(qq.tolist())
# #Add Node Names
kite_d.vs['name'] = qq.dtype.names
# #Add Node Labels
kite_d.vs['label'] = kite_d.vs['name']

# #Get iGraph (Undirected) from Directed Graph
kite_u = copy.deepcopy(kite_d)
kite_u.to_undirected()

# #Summary
ig.summary(kite_d)
ig.summary(kite_u)

# #Copy
y_kite = copy.deepcopy(kite_u)

# #Get DataFrame from iGraph
ss = pd.DataFrame(y_kite.get_adjacency().data, columns = y_kite.vs['name'], dtype = np.int32)
assert(pp.equals(ss))

# #Indices
print(y_kite.vs.indices)
print(y_kite.vs['name'])
print(y_kite)

```

### Layout {.tabset .tabset-fade}

#### R {.unlisted .unnumbered}

```{r 'P01-R-Layout-Kite', decorate=TRUE}
# #Attaching a default layout to the Network for ease of comparison
if(FALSE) {
  # #Generate a Layout Matrix of Coordinates
  set.seed(3)
  # #Layout: Fruchterman Reingold layout_with_fr () or Kamada Kawai layout_with_kk()
  ii <- round(layout_with_fr(r_kite), 1)
  dput(ii)
  #matrix(c(9.8, 11.1, 9.3, 10.6, 11.9, 10.4, 11.5, 11.5, 12.1, 12.7, 
  #         6.1, 5.7, 6.9, 6.5, 6, 7.5, 7.1, 8.8, 10.6, 12), ncol = 2, byrow = FALSE) 
  #matrix(c(9.8, 6.1, 11.1, 5.7, 9.3, 6.9, 10.6, 6.5, 11.9, 6, 
  #         10.4, 7.5, 11.5, 7.1, 11.5, 8.8, 12.1, 10.6, 12.7, 12), ncol = 2, byrow = TRUE)
}
# #Attach Layout Coordinates as Graph Attribute
graph_attr(r_kite, "layout") <- matrix(c(9.8, 6.1, 11.1, 5.7, 9.3, 6.9, 10.6, 6.5, 11.9, 6, 
            10.4, 7.5, 11.5, 7.1, 11.5, 8.8, 12.1, 10.6, 12.7, 12), ncol = 2, byrow = TRUE)
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-Layout-Kite', decorate=TRUE}
pp = [[9.8, 6.1], [11.1, 5.7], [9.3, 6.9], [10.6, 6.5], [11.9, 6], 
      [10.4, 7.5], [11.5, 7.1], [11.5, 8.8], [12.1, 10.6], [12.7, 12]]
if(False): ig.plot(y_kite, layout = pp)

# #Set Visual Style
visual_style = {}
#visual_style["layout"] = y_kite.layout_fruchterman_reingold()
visual_style["layout"] = pp

if(False): ig.plot(y_kite, **visual_style)

```

### Vertices or Nodes {.tabset .tabset-fade}

#### R {.unlisted .unnumbered}

```{r 'P01-R-Vertices-Kite', decorate=TRUE}
bb <- r_kite
# #Count Vertices
vcount(bb)
#
# #Named Vector of Vertices
V(bb)
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-Vertices-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Count Vertices
pp.vcount()

# #List of Vertices
pp.vs['name']

```

### Edges or Links {.tabset .tabset-fade}

#### R {.unlisted .unnumbered}

```{r 'P01-R-Edges-Kite', decorate=TRUE}
bb <- r_kite
# #Count Edges
ecount(bb)

# #Named Vector of Edges
E(bb)
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-Edges-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Count Edges
pp.ecount()

# #List of Edges - EdgeList and unnamed #ForLater
#print(pp)
pp.get_edgelist() #Not Named

#qq = pp.es.select(_within=[0,1,2,3,4,5,6,7,8,9])
#qq = pp.es.select(_within=pp.vs[0:9])
#qq.indices #Gives the Edges Sequence

```

### Edgelist & iGraph {.tabset .tabset-fade}

#### R {.unlisted .unnumbered}

```{r 'P01-R-EdgeList-Kite', decorate=TRUE}
bb <- r_kite
#
# #Get Edgelist from iGraph
ii <- as_edgelist(bb, names = TRUE)
class(ii)
str(ii)
head(ii)
#
# #Get iGraph from Edgelist
jj <- graph_from_edgelist(ii)
#
kk <- attributes(E(bb))$vnames
ll <- attributes(E(jj))$vnames
stopifnot(identical(kk, ll))
#
ll
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-EdgeList-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Get Edgelist from iGraph - Unnamed #Later
pp.get_edgelist() #Not Named

```

### Shortest Paths {.tabset .tabset-fade}

- The \textcolor{pink}{shortest paths} matrix shows us the minimum number of edges between each member (degrees of separation)
  - The shortest path length from a vertex to itself is always zero. 

#### R {.unlisted .unnumbered}

```{r 'P01-R-Shortest-Paths-Kite', decorate=TRUE}
bb <- r_kite
# #Histogram of the shortest path length between each pair of vertices.
distance_table(bb)
#
# #Numeric matrix with length(to) columns and length(v) rows. 
distances(bb, mode = "all")
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-Shortest-Paths-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)

# #ForLater
pp.get_all_shortest_paths(v=0)
pp.get_all_shortest_paths(v="A")

```

### Diameter {.tabset .tabset-fade}

- The \textcolor{pink}{diameter} of a network tells us the number of edges between the most distant members
  - The diameter of a graph is the length of the longest geodesic.

#### R {.unlisted .unnumbered}

```{r 'P01-R-Diameter-Kite', decorate=TRUE}
bb <- r_kite
# #Diameter
diameter(bb)
#
# #Two vertex ids, the vertices which are connected by the diameter path.
farthest_vertices(bb)
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-Diameter-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Diameter
pp.get_diameter()

# #Subset a List by index
[pp.vs['name'][i] for i in pp.get_diameter()]

# #Two vertex ids, the vertices which are connected by the diameter path.
pp.farthest_points()

```

### Reciprocity {.tabset .tabset-fade}

- \textcolor{pink}{Reciprocity} is the ratio of the number of reciprocated edges to the number of total edges.

#### R {.unlisted .unnumbered}

```{r 'P01-R-Reciprocity-Kite', decorate=TRUE}
bb <- r_kite
# #Reciprocity
reciprocity(bb)
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-Reciprocity-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Reciprocity
pp.reciprocity()

```

### Density or Clustering Coefficient {.tabset .tabset-fade}

- The \textcolor{pink}{density} or 'Clustering Coefficient' of a graph is the ratio of the number of edges and the number of possible edges.

#### R {.unlisted .unnumbered}

```{r 'P01-R-Density-Kite', decorate=TRUE}
bb <- r_kite
# #Density
edge_density(bb)
```

#### Python {.unlisted .unnumbered}

```{python 'P01-Y-Density-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Density
pp.density()

```

### Network {.tabset .tabset-fade}

#### Plot {.unlisted .unnumbered}

```{r 'P01-R-Plot-Kite', decorate=TRUE, include=FALSE}
hh <- r_kite
#
# #Use Degrees of each node to indicate size
size_m <- 5L 
size_hh <- degree(hh, mode = "all") * size_m
#
# #Distances of ALL Nodes from the Specified Node i.e. "D"
away_d <- distances(hh, v = V(hh)["D"], to = V(hh))
# #Get a Vector of same length with Maximum Unique Colors & accounting for 0 index
v_col_hh <- viridis(max(away_d) + 1, direction = -1)[away_d + 1]
v_lbl_col_hh <- c(rep("black", vcount(hh)-3), rep("white", 3))
#
# #Get Diameter Path
far_hh <- farthest_vertices(hh)$vertices
dia_hh <- shortest_paths(hh, from = V(hh)[far_hh[1]], to  = V(hh)[far_hh[2]], output = "both")
#
# #Edge color
e_col_hh <- rep("gray", ecount(hh))
e_col_hh[unlist(dia_hh$epath)] <- "orange"
# #Edge width
e_w_hh <- rep(2, ecount(hh))
e_w_hh[unlist(dia_hh$epath)] <- 4
# #Node color for the Path
#v_col_hh <- rep("gray", vcount(hh))
#v_col_hh[unlist(dia_hh$vpath)] <- "gold"
#
# #Color Legend
lgd_col_hh <- tibble(Text = unique(as.vector(away_d)), Fill = unique(v_col_hh)) |> arrange(Text)
lgd_ttl_col_hh <- "Distance"
# #Size Legend
lgd_size_hh <- sort(unique(size_hh))/size_m
lgd_ttl_size_hh <- "Degree"
#
ttl_hh <- "Krackhardt Kite: Degrees, Diameter, and Distances from D" 
cap_hh <- "P01I01"
loc_png <- here("images", "P01I01-Kite.png") 
#
if(FALSE | !file.exists(loc_png)) {
  png(filename = loc_png, width = q_png_w, height = q_png_h, units = "in", res = q_dpi)
  #dev.control('enable') 
  plot(hh, vertex.size = size_hh, vertex.color = v_col_hh, vertex.label.color = v_lbl_col_hh, 
       edge.color = e_col_hh, edge.width = e_w_hh)
  legend(x = "topleft", inset = 0.2, legend = lgd_col_hh$Text, pt.bg = lgd_col_hh$Fill, 
         pch = 21, pt.cex = 3, cex = 1.3, title = lgd_ttl_col_hh)
  legend(x = "topleft", legend = seq.int(lgd_size_hh), pt.cex = lgd_size_hh, 
         pch = 1, cex = 1.3, x.intersp = 1.5, y.intersp = 1.5, title = lgd_ttl_size_hh)
  title(main = ttl_hh, line = 3, adj = 0)
  title(sub = cap_hh, line = 4, adj = 1)
  P01 <- recordPlot()
  dev.off()
  assign(cap_hh, P01)
  rm(P01)
  #eval(parse(text = cap_hh))
}
```

```{r 'P01I01', echo=FALSE, fig.cap="(P01I01) Krackhardt Kite"}
include_graphics(here("images", "P01I01-Kite.png"))
```

#### Code {.unlisted .unnumbered}

```{r 'P01-R-Plot-Kite-A', decorate=TRUE, eval=FALSE, ref.label=c('P01-R-Plot-Kite')}
#
```

### Centrality

#### Degree Centrality {.tabset .tabset-fade}

- The \textcolor{pink}{degree} of a vertex is the number connections (adjacent edges) for a node

##### R {.unlisted .unnumbered}

```{r 'P01-R-Centrality-Degree-Kite', decorate=TRUE}
bb <- r_kite
# #Vector of each Vertex Degree: mode = c("all", "out", "in", "total")
degree(bb, mode = "all")
```

##### Python {.unlisted .unnumbered}

```{python 'P01-Y-Centrality-Degree-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Dictionary of each Vertex Degree by combining Two Lists
qq = dict(zip(pp.vs['name'], pp.degree(), strict = True))
#qq.keys()
#qq.values()
#print(qq.items())
print(qq)
for key, value in qq.items(): print(key + " : " + value.__str__())

```

#### Closeness Centrality {.tabset .tabset-fade}

- \textcolor{pink}{Closeness centrality} measures how many steps is required to access every other vertex from a given vertex.
  - Normalized closeness centrality shows the inverse of the number of edges to all other nodes in the graph (e.g. a value of .5 means an average of two edges)

##### R {.unlisted .unnumbered}

```{r 'P01-R-Centrality-Closeness-Kite', decorate=TRUE}
bb <- r_kite
# #Vector of each Vertex Closeness: mode = c("all", "out", "in", "total")
closeness(bb, mode = "all", normalized = TRUE) |> round(3)
```

##### Python {.unlisted .unnumbered}

```{python 'P01-Y-Centrality-Closeness-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Dictionary of each Vertex Closeness by combining Two Lists
qq = [round(i, 3) for i in pp.closeness()]
ss = dict(zip(pp.vs['name'], qq, strict = True))
print(ss)
for key, value in ss.items(): print(key + " : " + value.__str__())

```

#### Betweenness Centrality {.tabset .tabset-fade}

- \textcolor{pink}{Betweenness centrality} shows the number of shortest paths a node is on between pairs of other nodes. 
  - If multiple shortest paths between two nodes exist the betweenness is shared among all the intermediate nodes

##### R {.unlisted .unnumbered}

```{r 'P01-R-Centrality-Betweenness-Kite', decorate=TRUE}
bb <- r_kite
# #Betweenness returns a 'communities' object
ii <- cluster_edge_betweenness(bb) 
attributes(ii)
str(ii)
#
# #Modularity
modularity(ii)
#
# #Group Sizes
sizes(ii)
#
# #Groups
setNames(ii$membership, nm = ii$names)
#
# #First Group
ii[[1]]
```

##### Python {.unlisted .unnumbered}

```{python 'P01-Y-Centrality-Betweenness-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)
# #Betweenness returns a 'communities' object
qq = [round(i, 3) for i in pp.betweenness()]
print(qq)

#cl = ig.Clustering(pp.vs()['group'])
#print(cl)
#pp.modularity(membership=cl)
#ig.VertexClustering(pp, pp.vs["group"])

# #ForLater

```

#### Eigenvector Centrality or Pagerank {.tabset .tabset-fade}

- \textcolor{pink}{Eigenvector centrality} or Pagerank scores correspond to the values of the first eigenvector of the graph adjacency matrix; these scores may, in turn, be interpreted as arising from a reciprocal process in which the centrality of each actor is proportional to the sum of the centralities of those actors to whom he or she is connected. 
  - In general, vertices with high eigenvector centralities are those which are connected to many other vertices which are, in turn, connected to many others.
  - It is a recursive measure of centrality, measuring each node by not only the number of connections it has, but weighting that metric by how many connections its connections have, which are in turn weighted by their connections etc. 

##### R {.unlisted .unnumbered}

```{r 'P01-R-Centrality-Eigenvector-Kite', decorate=TRUE}
bb <- r_kite
# #List of Eigenvector and Eigenvalue Score
ii <- eigen_centrality(bb) 
#
# #Eigenvector of each Vertex
ii$vector |> round(3)
#
# #Eigenvalue Score
ii$value
```

##### Python {.unlisted .unnumbered}

```{python 'P01-Y-Centrality-Eigenvector-Kite', decorate=TRUE}
pp = copy.deepcopy(y_kite)

# #List of Eigenvector
qq = [round(i, 3) for i in pp.eigenvector_centrality()]
ss = dict(zip(pp.vs['name'], qq, strict = True))
print(ss)
for key, value in ss.items(): print(key + " : " + value.__str__())

# #Eigenvalue Score - #ForLater

```

#### Degree & Eigenvalue {.tabset .tabset-fade}

- Residual of Simple Linear Regression can be used to size the nodes in our network. This may identify nodes which are connected to only a few nodes, which are "important" i.e. they have high eigenvector centrality.

- #ForLater - Python igraph

##### R {.unlisted .unnumbered}

```{r 'P01-R-Degree-Eigenvector-Kite', decorate=TRUE}
bb <- r_kite
ii_deg <- degree(bb, mode = "all")
ii_egn <- eigen_centrality(bb)$vector
# #Tibble
ii <- tibble(Vertices = names(ii_deg), Degree = ii_deg, Eigen = ii_egn)
# #Regression
ii_res <- lm(Eigen ~ Degree, data = ii)$residuals |> round(7)
# #Add Residuals
ii |> add_column(Residual = ii_res) |> mutate(Size = abs(Residual)*100)
```


### Cliques {.tabset .tabset-fade}

- \textcolor{pink}{Cliques} are sets of nodes which are all connected to one another. 
  - To be included in a clique, a node must be tied to all other nodes in the clique.
  - A \textcolor{pink}{k-core} is a group where nodes have k edges within the group.
    - The k-core of graph is a maximal subgraph in which each vertex has at least degree k. 
    - The coreness of a vertex is k if it belongs to the k-core but not to the (k+1)-core.
    - Two nodes with coreness of 3 may not be connected at all and may be in separate k-cores.
  - NOTE: Directed graphs will be considered as Undirected ones for Cliques calculation
  
```{r 'P01-R-Cliques-Kite', decorate=TRUE}
bb <- r_kite
# #Max Cliques with Lengths
summary(max_cliques(bb))[, 1]
#
# #Largest Cliques
largest_cliques(bb)
#
# #Coreness
coreness(bb)
```

#### Plot {.unlisted .unnumbered}

```{r 'P01-R-Plot-Kite-Cliques', decorate=TRUE, include=FALSE}
hh <- r_kite
#
# #Get Largest Cliques
cliq_hh <- largest_cliques(hh)
# #Color Cliques
pal_hh <- viridis(length(cliq_hh) + 1) #Palette
v_col_hh <- rep(last(pal_hh), vcount(hh))
v_col_hh[cliq_hh[[1]]] <- pal_hh[1]
v_col_hh[cliq_hh[[2]]] <- pal_hh[2]
#
# #Text Label Color
v_lbl_col_hh <- c(rep("black", vcount(hh)))
v_lbl_col_hh[cliq_hh[[1]]] <- "white"
v_lbl_col_hh[cliq_hh[[2]]] <- "white"
#
ttl_hh <- "Krackhardt Kite: Cliques" 
cap_hh <- "P01I02"
loc_png <- here("images", "P01I02-Kite-Cliques.png") 
#
if(FALSE | !file.exists(loc_png)) {
  png(filename = loc_png, width = q_png_w, height = q_png_h, units = "in", res = q_dpi)
  #dev.control('enable') 
  plot(hh, vertex.color = v_col_hh, vertex.label.color = v_lbl_col_hh, mark.groups = cliq_hh)
  title(main = ttl_hh, line = 3, adj = 0)
  title(sub = cap_hh, line = 4, adj = 1)
  P01 <- recordPlot()
  dev.off()
  assign(cap_hh, P01)
  rm(P01)
  #eval(parse(text = cap_hh))
}
```

```{r 'P01I02', echo=FALSE, fig.cap="(P01I02) Krackhardt Kite: Cliques"}
include_graphics(here("images", "P01I02-Kite-Cliques.png"))
```

#### Code {.unlisted .unnumbered}

```{r 'P01-R-Plot-Kite-Cliques-A', decorate=TRUE, eval=FALSE, ref.label=c('P01-R-Plot-Kite-Cliques')}
#
```

## Community Detection & Modularity {.tabset .tabset-fade}

- Popular algorithms for finding structure in large graphs
  - \textcolor{pink}{Walktrap} algorithm 
    - It detects communities through a series of short random walks, with the idea that the nodes encountered on any given random walk are more likely to be within a community than not. 
    - While edge betweenness started with the whole network and removed edges to create clusters, this algorithm initially treats all nodes as communities of their own, then merges them into communities, and these communities into larger communities, and so on.
  - \textcolor{pink}{Fast Greedy} algorithm 
    - The time walktrap algorithm takes to run grows with the square of the number of nodes times the number of edges $O(|V| |E|^2)$. 
    - Fast greedy algorithm takes less time to run as the network size increases $O(|V| |E| \log{|V|})$.
- \textcolor{pink}{Modularity} is one way to measure of the success of a community finding algorithm. 
  - The higher the modularity, the more dense edges within groups are and the more sparse edges reaching outside of the groups are. i.e. \textcolor{pink}{Higher is Better}.

### R {.unlisted .unnumbered}

```{r 'P01-R-Community', decorate=TRUE}
bb <- r_kite
# #Betweenness Centrality: Slow
btw <- cluster_edge_betweenness(bb) 
# #Modularity
modularity(btw) |> round(3)
# #Group Sizes
sizes(btw)
# #Groups
setNames(btw$membership, nm = btw$names)
#
# #Walktrap Algorithm
walk <- cluster_walktrap(bb)
# #Modularity
modularity(walk) |> round(3)
# #Group Sizes
sizes(walk)
# #Groups
setNames(walk$membership, nm = walk$names)
#
# #Fast Greedy Algorithm
greed <- cluster_fast_greedy(bb)
# #Modularity
modularity(greed) |> round(3)
# #Group Sizes
sizes(greed)
# #Groups
setNames(greed$membership, nm = greed$names)
```

### Python {.unlisted .unnumbered}

## Community Detection Algorithms {.tabset .tabset-fade}

### Plot {.unlisted .unnumbered}

```{r 'P01-R-Plot-Kite-Communities', decorate=TRUE, include=FALSE}
hh <- r_kite
hh_b <- cluster_edge_betweenness(hh) 
hh_w <- cluster_walktrap(hh)
hh_g <- cluster_fast_greedy(hh)
#
#ttl_hh <- "Krackhardt Kite: Communities" 
ttl_hh_b <- "Kite: Betweenness" 
ttl_hh_w <- "Kite: Walktrap" 
ttl_hh_g <- "Kite: Fast Greedy" 
cap_hh <- "P01I03"
loc_png <- here("images", "P01I03-Kite-Communities.png") 
#
if(FALSE | !file.exists(loc_png)) {
  png(filename = loc_png, width = q_png_w_w, height = q_png_w_h, units = "in", res = q_dpi_w)
  #dev.control('enable') 
  def_par <- par(no.readonly = TRUE) #Save Default
  par(mfrow = c(2, 3), mar = c(0,0,0,0))
  plot(x = hh_b, y = hh)
  title(main = ttl_hh_w, line = -2, adj = 0.5)
  plot(x = hh_w, y = hh)
  title(main = ttl_hh_b, line = -2, adj = 0.5)
  plot(x = hh_g, y = hh)
  title(main = ttl_hh_g, line = -2, adj = 0.5)
  plot_dendrogram(x = hh_b, cex = 2)
  plot_dendrogram(x = hh_w, cex = 2)
  plot_dendrogram(x = hh_g, cex = 2)
  par(def_par)  #Reset Default
  title(sub = cap_hh, line = 4, adj = 1)
  P01 <- recordPlot()
  dev.off()
  #par(mfrow = c(1, 1)) #Default
  assign(cap_hh, P01)
  rm(P01)
  #eval(parse(text = cap_hh))
}
```

```{r 'P01I03', echo=FALSE, out.width='100%', fig.cap="(P01I03) Krackhardt Kite: Communities"}
include_graphics(here("images", "P01I03-Kite-Communities.png"))
```

### Code {.unlisted .unnumbered}

```{r 'P01-R-Plot-Kite-Communities-A', decorate=TRUE, eval=FALSE, ref.label=c('P01-R-Plot-Kite-Communities')}
#
```

## Validation {#val-p01 .unlisted .unnumbered .tabset .tabset-fade}

```{r 'P01-R-Cleanup', decorate=TRUE, include=FALSE, cache=FALSE}
if(FALSE) f_rmExist(aa, bb, ii, jj, kk, ll, loc_rds, loc_src, names_ii, p01r_km_1, p01r_km_4)
```

```{r 'P01-R-Validation', decorate=TRUE, include=TRUE, cache=FALSE}
# #SUMMARISED Packages and Objects (BOOK CHECK)
f_()
#
difftime(Sys.time(), q_start)
```

****
